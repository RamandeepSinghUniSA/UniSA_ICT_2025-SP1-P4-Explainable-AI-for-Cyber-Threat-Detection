{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the UNSW-NB15 Dataset\n",
    "\n",
    "In this part, the preprocessing of the dataset is performed. The steps followed in this part are as follows:\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Loading the Dataset**\n",
    "   - Load the UNSW-NB15 dataset from a CSV file into a pandas DataFrame for further processing.\n",
    "\n",
    "2. **Encoding Categorical Features**\n",
    "   - Convert categorical features into numerical values using label encoding. This is necessary for machine learning algorithms that require numerical input.\n",
    "\n",
    "3. **Scaling Numerical Features**\n",
    "   - Standardize the numerical features by scaling them to have zero mean and unit variance. This helps in improving the performance of machine learning models.\n",
    "\n",
    "4. **Splitting the Dataset into Training and Testing Sets**\n",
    "   - Split the dataset into training and testing sets to evaluate the performance of machine learning models. Typically, 80% of the data is used for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations and arrays\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting in Jupyter notebooks\n",
    "# Fixed duplicate import and invalid syntax\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "Load the Cleaned Dataset.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>33661</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>1024</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.6</td>\n",
       "      <td>1464</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>3593</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>49664</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        srcip  sport          dstip dsport proto state       dur  sbytes  \\\n",
       "0  59.166.0.0   1390  149.171.126.6     53   udp   CON  0.001055     132   \n",
       "1  59.166.0.0  33661  149.171.126.9   1024   udp   CON  0.036133     528   \n",
       "2  59.166.0.6   1464  149.171.126.7     53   udp   CON  0.001119     146   \n",
       "3  59.166.0.5   3593  149.171.126.5     53   udp   CON  0.001209     132   \n",
       "4  59.166.0.3  49664  149.171.126.0     53   udp   CON  0.001169     146   \n",
       "\n",
       "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
       "0     164    31  ...         0.0           3           7          1   \n",
       "1     304    31  ...         0.0           2           4          2   \n",
       "2     178    31  ...         0.0          12           8          1   \n",
       "3     164    31  ...         0.0           6           9          1   \n",
       "4     178    31  ...         0.0           7           9          1   \n",
       "\n",
       "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \\\n",
       "0           3                 1                 1               1      Normal   \n",
       "1           3                 1                 1               2      Normal   \n",
       "2           2                 2                 1               1      Normal   \n",
       "3           1                 1                 1               1      Normal   \n",
       "4           1                 1                 1               1      Normal   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "# Reading datasets\n",
    "# Using list comprehension to read all csv files in 4 csv files\n",
    "df = pd.read_csv('C:/Users/raman/OneDrive/Important/1UnisaSTUDY/Courses/Capstone_Project_1/Github/Code Working/Data Cleaning and EDA/Cleaned_full_data.csv', header=0) \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2540047, 49)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Full data is avaliable or not\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Encoding Categorical Features**\n",
    "   - Convert categorical features into numerical values using label encoding. This is necessary for machine learning algorithms that require numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode categorical features\n",
    "# Label Encoding: Converts categories to numerical values (0,1,2...). Good for ordinal data but can imply ordering\n",
    "# One-Hot Encoding: Creates binary columns for each category. Better for nominal data with no inherent order\n",
    "def encode_categorical_features(df, categorical_features, encoding_type='label'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        categorical_features: List of categorical column names\n",
    "        encoding_type: 'label' for LabelEncoder or 'onehot' for OneHotEncoder\n",
    "    \"\"\"\n",
    "    if encoding_type == 'label':\n",
    "        label_encoders = {}\n",
    "        for column in categorical_features:\n",
    "            label_encoders[column] = LabelEncoder()\n",
    "            df[column] = label_encoders[column].fit_transform(df[column].astype(str))\n",
    "        return df, label_encoders\n",
    "    \n",
    "    elif encoding_type == 'onehot':\n",
    "        onehot = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        encoded_array = onehot.fit_transform(df[categorical_features])\n",
    "        \n",
    "        # Create new column names for one-hot encoded features\n",
    "        new_columns = []\n",
    "        for i, feature in enumerate(categorical_features):\n",
    "            categories = onehot.categories_[i]\n",
    "            new_columns.extend([f\"{feature}_{cat}\" for cat in categories])\n",
    "            \n",
    "        # Create new dataframe with encoded features\n",
    "        encoded_df = pd.DataFrame(encoded_array, columns=new_columns, index=df.index)\n",
    "        \n",
    "        # Drop original categorical columns and concat encoded ones\n",
    "        df = df.drop(columns=categorical_features)\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "        return df, onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling Numerical Features**\n",
    "   - Standardize the numerical features by scaling them to have zero mean and unit variance. This helps in improving the performance of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scale numerical features\n",
    "def scale_numerical_features(df, numerical_features):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the Dataset into Training and Testing Sets**\n",
    "   - Use `train_test_split` from the `sklearn.model_selection` module to split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset into training and testing sets\n",
    "def split_dataset(df, target_column, test_size=0.2, random_state=42):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Training set size: (2032037, 48)\n",
      "Test set size: (508010, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function to preprocess the dataset\n",
    "def preprocess_unsw_nb15(df, target_column, categorical_features, numerical_features, encoding_type='label'):\n",
    "    df, encoders = encode_categorical_features(df, categorical_features, encoding_type)\n",
    "    df, scaler = scale_numerical_features(df, numerical_features)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(df, target_column)\n",
    "    return X_train, X_test, y_train, y_test, encoders, scaler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is already loaded and categorical and numerical features are identified\n",
    "    target_column = 'label'  # Update with the correct target column\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_features = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "\n",
    "    # Preprocessing\n",
    "    encoding_type = 'label'  # Change to 'onehot' for One-Hot Encoding\n",
    "    X_train, X_test, y_train, y_test, encoders, scaler = preprocess_unsw_nb15(df, target_column, categorical_features, numerical_features, encoding_type)\n",
    "    print(\"Preprocessing complete.\")\n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set head:\n",
      "         srcip  sport  dstip  dsport  proto  state       dur    sbytes  \\\n",
      "596843      38  49373     27   54769    114      5 -0.046008 -0.031869   \n",
      "593275      42  30709     25   37620    114      5 -0.045501 -0.012864   \n",
      "1254949     35  42244     26   35345    114      5 -0.046083 -0.028181   \n",
      "191973      34  42875     21   51807    120      2 -0.047183 -0.067574   \n",
      "2185322     35  38677     21   51652    114      5 -0.046969 -0.011694   \n",
      "\n",
      "           dbytes      sttl  ...  is_ftp_login  ct_ftp_cmd  ct_srv_src  \\\n",
      "596843  -0.080670 -0.425902  ...     -0.132116   -0.170489   -0.203658   \n",
      "593275   0.058514 -0.425902  ...     -0.132116   -0.170489   -0.203658   \n",
      "1254949 -0.054673 -0.425902  ...     -0.132116         NaN   -0.665051   \n",
      "191973  -0.224236 -0.425902  ...     -0.132116   -0.170489    0.534571   \n",
      "2185322 -0.210878 -0.425902  ...     -0.132116         NaN   -0.019101   \n",
      "\n",
      "         ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
      "596843    -0.460981   -0.421354   -0.109809          -0.42962   \n",
      "593275     0.093421   -0.543872   -0.475437          -0.42962   \n",
      "1254949   -0.183780   -0.666391   -0.353561          -0.42962   \n",
      "191973     0.001020   -0.176317    0.499571          -0.42962   \n",
      "2185322   -0.276180   -0.298835   -0.353561          -0.42962   \n",
      "\n",
      "         ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \n",
      "596843          -0.419913       -0.519252           7  \n",
      "593275          -0.419913       -0.519252           7  \n",
      "1254949         -0.419913       -0.519252           7  \n",
      "191973          -0.419913       -0.163958           7  \n",
      "2185322         -0.419913       -0.341605           7  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "596843    -0.380529\n",
      "593275    -0.380529\n",
      "1254949   -0.380529\n",
      "191973    -0.380529\n",
      "2185322   -0.380529\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Test set head:\n",
      "         srcip  sport  dstip  dsport  proto  state       dur    sbytes  \\\n",
      "53230       38  61382     24   12108    114      5  0.016152 -0.024919   \n",
      "1823779     41  22917     26    1158    114      5 -0.023480  0.020324   \n",
      "2479738     10    453     28   47344    120      6 -0.047310 -0.072255   \n",
      "923745      38   3705     20   47344    120      2 -0.047230 -0.074630   \n",
      "1700724     40  27477      9   62606    114      5  0.033321 -0.048924   \n",
      "\n",
      "           dbytes      sttl  ...  is_ftp_login  ct_ftp_cmd  ct_srv_src  \\\n",
      "53230   -0.202895 -0.425902  ...      7.569107    3.435429   -0.757329   \n",
      "1823779  0.361663 -0.425902  ...     -0.132116         NaN   -0.388215   \n",
      "2479738 -0.226124 -0.037281  ...     -0.132116         NaN    2.011028   \n",
      "923745  -0.225118 -0.425902  ...     -0.132116   -0.170489   -0.757329   \n",
      "1700724 -0.163006 -0.425902  ...     -0.132116         NaN   -0.757329   \n",
      "\n",
      "         ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
      "53230     -0.738181   -0.053798   -0.475437         -0.429620   \n",
      "1823779   -0.738181   -0.421354   -0.475437         -0.429620   \n",
      "2479738    2.033825    3.009164    2.937092          3.109127   \n",
      "923745    -0.553381   -0.543872   -0.597313         -0.429620   \n",
      "1700724   -0.645781    0.313757   -0.353561         -0.429620   \n",
      "\n",
      "         ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \n",
      "53230           -0.419913       -0.341605           7  \n",
      "1823779         -0.419913       -0.519252           7  \n",
      "2479738          1.847498        2.145453           7  \n",
      "923745          -0.419913       -0.519252           7  \n",
      "1700724         -0.419913       -0.519252           7  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "53230     -0.380529\n",
      "1823779   -0.380529\n",
      "2479738   -0.380529\n",
      "923745    -0.380529\n",
      "1700724   -0.380529\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print head values\n",
    "print(\"\\nTraining set head:\")\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"\\nTest set head:\")\n",
    "print(X_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#X_train.to_csv('X_train.csv', index=False)\n",
    "#X_test.to_csv('X_test.csv', index=False)\n",
    "#y_train.to_csv('y_train.csv', index=False)\n",
    "#y_test.to_csv('y_test.csv', index=False)\n",
    "#print(\"CSV files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle files saved.\n"
     ]
    }
   ],
   "source": [
    "# Save to pickle\n",
    "output_folder = 'C:/Users/raman/OneDrive/Important/1UnisaSTUDY/Courses/Capstone_Project_1/Github/Code Working/Pickle'  # Change this to your desired folder\n",
    "\n",
    "# Ensure the output folder exists\n",
    "import os\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_folder, 'X_train.pkl'), 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(os.path.join(output_folder, 'X_test.pkl'), 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open(os.path.join(output_folder, 'y_train.pkl'), 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open(os.path.join(output_folder, 'y_test.pkl'), 'wb') as f:\n",
    "    pickle.dump(y_test, f)\n",
    "print(\"Pickle files saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
