{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Import Libraries\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations and arrays\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting in Jupyter notebooks\n",
    "# Fixed duplicate import and invalid syntax\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Load the full datset after Combined Raw Dataset given in 4 CSV Files.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Reading datasets\n",
    "# Using list comprehension to read all csv files in 4 csv files\n",
    "df = pd.read_csv('C:/Users/raman/OneDrive/Important/1UnisaSTUDY/Courses/Capstone_Project_1/Github/Code Working/Data Cleaning and EDA/full_data.csv', header=0) \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "In this section we are trying to find the unique values in the dataset also NAN or null values columns.\n",
    "\n",
    "The following three columns have null values\n",
    "\n",
    "- ct_flw_http_mthd:  No. of flows that has methods such as Get and Post in http service. \n",
    "\n",
    "- is_ftp_login: If the ftp session is accessed by user and password then 1 else 0.\n",
    "\n",
    "- attack_cat: The name of each attack category. In this data set, nine categories (e.g., Fuzzers, Analysis, Backdoors, DoS, Exploits,Generic, Reconnaissance, Shellcode and Worms)  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find all the unique values in this DataFrame and count how many times each appears\n",
    "df.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with missing values by checking for NaN values across all columns (axis=1)\n",
    "missing_rows = df[df.isna().any(axis=1)]\n",
    "# Get column names where missing values were found in the subset of rows with missing values\n",
    "missing_cols = missing_rows.columns[missing_rows.isna().any()]\n",
    "# Print summary of number of rows found with missing values\n",
    "print(f\"\\nFound {len(missing_rows)} rows with missing values in columns:\")\n",
    "# Print names of columns containing missing values\n",
    "print(missing_cols)\n",
    "# Print the subset of rows and columns containing missing values\n",
    "print(missing_rows[missing_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the sum for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In this section we cleared the null values from the following section:\n",
    "\n",
    "- ct_flw_http_mthd:  No. of flows that has methods such as Get and Post in http service. \n",
    "\n",
    "There were 1348145 null values converted into 0.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values before filling\n",
    "print(\"Number of null values before:\", df['ct_flw_http_mthd'].isnull().sum())\n",
    "\n",
    "# Check unique values before transformation\n",
    "print(\"\\nUnique values before:\")\n",
    "print(df['ct_flw_http_mthd'].unique())\n",
    "\n",
    "# Show value counts before transformation\n",
    "print(df['ct_flw_http_mthd'].value_counts())\n",
    "\n",
    "# Fill null values with 0\n",
    "df['ct_flw_http_mthd'] = df['ct_flw_http_mthd'].fillna(0)\n",
    "\n",
    "# Check unique values after transformation\n",
    "print(\"\\nUnique values after:\")\n",
    "print(df['ct_flw_http_mthd'].unique())\n",
    "\n",
    "# Show value counts after transformation\n",
    "print(\"\\nValue counts after:\")\n",
    "print(df['ct_flw_http_mthd'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In this section we cleared the null values from the following section:\n",
    "\n",
    "- is_ftp_login:  If the ftp session is accessed by user and password then 1 else 0.  \n",
    "\n",
    "There were 1429879 null values converted into 0.\n",
    "\n",
    "and 4.0 has 156 values and 2.0 has 30 values in this section.\n",
    "\n",
    "These values above 1 were converted into 1 value.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check initial null values and unique values\n",
    "print(\"Initial null values:\", df['is_ftp_login'].isnull().sum())\n",
    "print(\"\\nInitial unique values:\")\n",
    "print(df['is_ftp_login'].unique())\n",
    "print(df['is_ftp_login'].value_counts())\n",
    "\n",
    "# Fill nulls with 0 and cap values at 1 to create binary column\n",
    "df['is_ftp_login'] = df['is_ftp_login'].fillna(0)\n",
    "df['is_ftp_login'] = np.where(df['is_ftp_login']>1, 1, df['is_ftp_login'])\n",
    "\n",
    "# Show final value distribution\n",
    "print(\"\\nFinal value counts:\")\n",
    "print(df['is_ftp_login'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In this section we cleared the null values from the following section:\n",
    "\n",
    "- attack_cat:  If the ftp session is accessed by user and password then 1 else 0.  \n",
    "\n",
    "There were 2218764 null values converted as Normal.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have \"Normal\" values for \"attack_cat\", so we must fill Null values with \"normal\"\n",
    "# This code performs two operations on the 'attack_cat' column of a dataframe:\n",
    "# 1. Fills any null/missing values with the string 'normal' using fillna()\n",
    "# Check for null values before filling\n",
    "print(\"Number of null values before:\", df['attack_cat'].isnull().sum())\n",
    "\n",
    "# Check unique values before transformation\n",
    "print(\"\\nUnique values before:\")\n",
    "print(df['attack_cat'].unique())\n",
    "\n",
    "# Apply the transformation\n",
    "df['attack_cat'] = df.attack_cat.fillna(value='Normal').apply(lambda x: x.strip())\n",
    "\n",
    "# Check for null values after filling\n",
    "print(\"\\nNumber of null values after:\", df['attack_cat'].isnull().sum())\n",
    "\n",
    "# Check unique values after transformation\n",
    "print(\"\\nUnique values after:\")\n",
    "print(df['attack_cat'].unique())\n",
    "\n",
    "# Get value counts to see distribution\n",
    "print(\"\\nValue counts:\")\n",
    "print(df['attack_cat'].value_counts())#    - Removes leading/trailing whitespace using strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Once again all datset unique values column wise checked and found some strange values in the following columns:\n",
    "\n",
    "- service: http, ftp, ssh, dns ..,else (-)\n",
    "\n",
    "This section got 1246397 values as - which is then converted into none.\n",
    "\n",
    "- ct_ftp_cmd:No of flows that has a command in ftp session. \n",
    "\n",
    "This section got numeric values with unique chracters like [0, 1, 6, 2, 4, 8, 5, 3, '0', '1', ' ', '2', '4']  which is the converted as '1' as 1.\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code iterates through each column in the DataFrame 'df'\n",
    "# For each column, it:\n",
    "# 1. Prints the column name\n",
    "# 2. Uses value_counts() to display how many times each unique value appears in that column\n",
    "# Display unique values and their counts for each column\n",
    "for column in df.columns:\n",
    "    print(f\"\\n{column}:\")\n",
    "    print(df[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each unique value in the 'service' column\n",
    "# Returns a Series with the value counts in descending order\n",
    "df['service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all instances of \"-\" with \"None\" in the 'service' column using more readable method\n",
    "df['service'] = df['service'].replace('-', 'none')\n",
    "# Get the count of unique values in the 'service' column after removing \"-\" with none\n",
    "df['service'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each unique value in the 'ct_ftp_cmd' column\n",
    "# Returns a Series with unique values as index and their counts as values\n",
    "df['ct_ftp_cmd'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in the 'ct_ftp_cmd' column of the dataframe\n",
    "# Returns array of distinct FTP commands used in the dataset\n",
    "\n",
    "df['ct_ftp_cmd'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values to correct categories (0-8)\n",
    "df['ct_ftp_cmd'] = df['ct_ftp_cmd'].map({\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    '1': 1,  # Convert string '1' to int 1\n",
    "    2: 2,\n",
    "    '2': 2,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    '4': 4,\n",
    "    5: 5,\n",
    "    6: 6,\n",
    "    8: 8\n",
    "})\n",
    "\n",
    "# Verify the cleanup\n",
    "print(df['ct_ftp_cmd'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "As most of the dataset is cleaned and can be downloaded into a Cleaned_full_data.csv csv file\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned DataFrame to a CSV file\n",
    "# The file will be saved in the current directory as 'Cleaned_full_data.csv'\n",
    "# index=False prevents the DataFrame index from being written to the CSV\n",
    "# This file will be too big to load in github so change the path to other location\n",
    "\n",
    "\n",
    "# df.to_csv('./Cleaned_full_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
