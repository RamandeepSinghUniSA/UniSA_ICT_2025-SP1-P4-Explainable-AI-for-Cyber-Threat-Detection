{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from explainerdashboard import ExplainerDashboard, ClassifierExplainer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import captum.attr as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_26556\\2584280520.py:1: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Cleaned_full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset retained index.\n",
    "data = data.reset_index(drop=True)\n",
    "# Set NA to 0.\n",
    "data['ct_ftp_cmd'] = data['ct_ftp_cmd'].fillna(0)\n",
    "data['attack_cat'] = data['attack_cat'].str.replace(r'\\s+', '', regex=True)\n",
    "data['attack_cat'] = data['attack_cat'].str.replace('Backdoors', 'Backdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['proto', 'dsport', 'service', 'state', 'srcip', 'sport', 'dstip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[['is_ftp_login', 'is_sm_ips_ports', 'label', 'attack_cat']]\n",
    "data = data.drop(columns=['is_ftp_login', 'is_sm_ips_ports', 'label', 'attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe1 = pd.read_csv('Full_proto_encoded.csv')\n",
    "ohe2 = pd.read_csv('Full_dsport_encoded.csv')\n",
    "ohe3 = pd.read_csv('Full_service_encoded.csv')\n",
    "ohe4 = pd.read_csv('Full_state_encoded.csv')\n",
    "# Spelling error.\n",
    "ohe5 = pd.read_csv('Full_scrip_encoded.csv')\n",
    "#------------------------------------------#\n",
    "ohe6 = pd.read_csv('Full_sport_encoded.csv')\n",
    "ohe7 = pd.read_csv('Full_dstip_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax seperates Normal data well and reduces noise. Please see Kmeans TSNE evaluation in Archive.\n",
    "#scaler = MinMaxScaler()\n",
    "#scaled_data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=data.columns)\n",
    "data = pd.concat([data, temp, ohe1, ohe2, ohe3, ohe4, ohe5, ohe6, ohe7], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, data['label'], test_size=0.2, random_state=42)\n",
    "# Drop attack cat before running model and store for later evaluation indexing.\n",
    "test_attack_cat = X_test['attack_cat']\n",
    "X_train = X_train.drop(columns=['attack_cat', 'label'])\n",
    "X_test = X_test.drop(columns=['attack_cat', 'label'])\n",
    "# Check label distribution.\n",
    "print(data['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RandomForest with default settings.\n",
    "# - Not sure why were getting a worse result here.\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RandomForest with default settings.\n",
    "# - Not sure why were getting a worse result here.\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=50)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance through Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            2218764\n",
      "Generic            215481\n",
      "Exploits            44525\n",
      "Fuzzers             24246\n",
      "DoS                 16353\n",
      "Reconnaissance      13987\n",
      "Analysis             2677\n",
      "Backdoor             2329\n",
      "Shellcode            1511\n",
      "Worms                 174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, data['label'], test_size=0.2, random_state=42)\n",
    "# Drop attack cat before running model and store for later evaluation indexing.\n",
    "test_attack_cat = X_test['attack_cat']\n",
    "X_train = X_train.drop(columns=['attack_cat', 'label'])\n",
    "X_test = X_test.drop(columns=['attack_cat', 'label'])\n",
    "# Check label distribution.\n",
    "print(data['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    443831\n",
      "           1       0.99      0.98      0.99     64179\n",
      "\n",
      "    accuracy                           1.00    508010\n",
      "   macro avg       0.99      0.99      0.99    508010\n",
      "weighted avg       1.00      1.00      1.00    508010\n",
      "\n",
      "[[443003    828]\n",
      " [  1054  63125]]\n"
     ]
    }
   ],
   "source": [
    "# Run RandomForest with default settings.\n",
    "# - Not sure why were getting a worse result here.\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "important_features = np.where(importances > 0)[0]\n",
    "X_train = X_train.iloc[:, important_features]\n",
    "X_test = X_test.iloc[:, important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    443831\n",
      "           1       0.99      0.98      0.99     64179\n",
      "\n",
      "    accuracy                           1.00    508010\n",
      "   macro avg       0.99      0.99      0.99    508010\n",
      "weighted avg       1.00      1.00      1.00    508010\n",
      "\n",
      "[[443009    822]\n",
      " [  1043  63136]]\n"
     ]
    }
   ],
   "source": [
    "# Run RandomForest with default settings.\n",
    "# - Not sure why were getting a worse result here.\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RandomForest with default settings.\n",
    "# - Not sure why were getting a worse result here.\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=50)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features of low importance Filtered through SHAP.\n",
    "Initially it causes much worse predictions but as I spend more time refining it we get closer to the original prediction with all variables. This was still a lazy approach and can be improved. I just need to finish my other Assignment then I will revisit this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct1 = ['proto_vines', 'proto_ib', 'proto_aes-sp3-d', 'proto_gmtp', 'proto_gmtp',\n",
    "        'proto_stp', 'proto_fc', 'proto_ipv6-opts', 'proto_larp', 'proto_pnni', 'proto_ipv6-route',\n",
    "        'proto_sat-expak', 'state_URH', 'proto_secure-vmtp', 'proto_pvp', 'proto_idrp',\n",
    "        'proto_encap', 'proto_fire', 'proto_iatp', 'proto_leaf-1', 'proto_emcon', 'proto_xtp',\n",
    "        'proto_tcf', 'proto_ipip', 'proto_micp', 'proto_mux', 'dstip_59.166.0.9', 'proto_scps',\n",
    "        'proto_mtp', 'proto_igp', 'proto_narp', 'proto_kryptolan', 'proto_cphb', 'proto_mfe-nsp',\n",
    "        'proto_cpnx', 'proto_uti', 'proto_zero', 'proto_tp++', 'proto_iplt', 'proto_ipx-n-ip',\n",
    "        'proto_ptp', 'srcip_149.171.126.0', 'proto_ax.25', 'proto_sccopmce', 'proto_sm',\n",
    "        'proto_ipv6-no', 'proto_xns-idp', 'proto_a/n', 'proto_vmtp', 'proto_crtp', 'proto_snp',\n",
    "        'proto_leaf-2', 'proto_pgm', 'proto_ipcv', 'proto_idpr-cmtp', 'proto_sprite-rpc',\n",
    "        'proto_compaq-peer', 'proto_ifmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct2 = ['proto_trunk-1', 'proto_dcn', 'proto_qnx', 'proto_wsn', 'proto_nsfnet-igp',\n",
    "            'proto_tlsp', 'proto_ipnip', 'proto_eigrp', 'proto_vrrp', 'proto_xnet', 'proto_iso-tp4',\n",
    "            'proto_mhrp', 'proto_isis', 'proto_irtp', 'proto_wb-mon', 'proto_visa', 'proto_il',\n",
    "            'proto_bbn-rcc', 'proto_cftp', 'proto_etherip', 'proto_iso-ip', 'proto_ddx', 'proto_wb-expak',\n",
    "            'proto_netblt', 'dstip_59.166.0.6', 'proto_idpr', 'proto_merit-inp', 'proto_hmp',\n",
    "            'proto_ipcomp', 'proto_ttp', 'proto_crudp', 'proto_skip', 'proto_srp', 'service_irc', 'proto_smp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct3 = ['srcip_149.171.126.5', 'state_CLO', 'dsport_631', 'proto_prm', 'sport_800', 'dstip_59.166.0.8', 'proto_3pc', 'proto_pri-enc', \n",
    "            'proto_pipe', 'proto_l2tp', 'srcip_149.171.126.2', 'dsport_6667','dstip_59.166.0.0', 'proto_dgp', 'dstip_59.166.0.0', 'proto_dgp',\n",
    "            'service_ssl', 'proto_pup', 'dstip_59.166.0.5', 'dstip_59.166.0.4',\n",
    "            'proto_rsvp', 'srcip_149.171.126.3', 'proto_ddp', 'dstip_59.166.0.1',\n",
    "            'dstip_59.166.0.2', 'dstip_59.166.0.7', 'srcip_149.171.126.1',\n",
    "            'dstip_59.166.0.3', 'srcip_149.171.126.13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=correct1)\n",
    "data = data.drop(columns=correct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=correct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            2218764\n",
      "Generic            215481\n",
      "Exploits            44525\n",
      "Fuzzers             24246\n",
      "DoS                 16353\n",
      "Reconnaissance      13987\n",
      "Analysis             2677\n",
      "Backdoor             2329\n",
      "Shellcode            1511\n",
      "Worms                 174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, data['label'], test_size=0.2, random_state=42)\n",
    "# Drop attack cat before running model and store for later evaluation indexing.\n",
    "test_attack_cat = X_test['attack_cat']\n",
    "X_train = X_train.drop(columns=['attack_cat', 'label'])\n",
    "X_test = X_test.drop(columns=['attack_cat', 'label'])\n",
    "# Check label distribution.\n",
    "print(data['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    443831\n",
      "           1       0.99      0.98      0.99     64179\n",
      "\n",
      "    accuracy                           1.00    508010\n",
      "   macro avg       0.99      0.99      0.99    508010\n",
      "weighted avg       1.00      1.00      1.00    508010\n",
      "\n",
      "[[443027    804]\n",
      " [  1038  63141]]\n"
     ]
    }
   ],
   "source": [
    "# Run RandomForest with default settings.\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    443831\n",
      "           1       0.99      0.98      0.99     64179\n",
      "\n",
      "    accuracy                           1.00    508010\n",
      "   macro avg       0.99      0.99      0.99    508010\n",
      "weighted avg       1.00      1.00      1.00    508010\n",
      "\n",
      "[[443012    819]\n",
      " [  1064  63115]]\n"
     ]
    }
   ],
   "source": [
    "# Run RandomForest with default settings.\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=50)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
