{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca7d6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from explainerdashboard import ExplainerDashboard, ClassifierExplainer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import captum.attr as c\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "\n",
    "#Tried XGBoost to increase the performance of the overall model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Assessing Gflops and Runtime\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7ac1157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matyc\\AppData\\Local\\Temp\\ipykernel_29372\\3121833706.py:1: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Cleaned_full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d86c4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset retained index.\n",
    "data = data.reset_index(drop=True)\n",
    "# Set NA to 0.\n",
    "data['ct_ftp_cmd'] = data['ct_ftp_cmd'].fillna(0)\n",
    "data['attack_cat'] = data['attack_cat'].str.replace(r'\\s+', '', regex=True)\n",
    "data['attack_cat'] = data['attack_cat'].str.replace('Backdoors', 'Backdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef318e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['proto', 'dsport', 'service', 'state', 'srcip', 'sport', 'dstip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b936b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[['is_ftp_login', 'is_sm_ips_ports', 'label', 'attack_cat']]\n",
    "data = data.drop(columns=['is_ftp_login', 'is_sm_ips_ports', 'label', 'attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e623e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe1 = pd.read_csv('../Full_proto_encoded.csv')\n",
    "ohe2 = pd.read_csv('../Full_dsport_encoded.csv')\n",
    "ohe3 = pd.read_csv('../Full_service_encoded.csv')\n",
    "ohe4 = pd.read_csv('../Full_state_encoded.csv')\n",
    "# Spelling error.\n",
    "ohe5 = pd.read_csv('../Full_scrip_encoded.csv')\n",
    "#------------------------------------------#\n",
    "ohe6 = pd.read_csv('../Full_sport_encoded.csv')\n",
    "ohe7 = pd.read_csv('../Full_dstip_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c448fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax seperates Normal data well and reduces noise. Please see Kmeans TSNE evaluation in Archive.\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "data = pd.concat([data, temp, ohe1, ohe2, ohe3, ohe4, ohe5, ohe6, ohe7], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ec54881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6    1774933\n",
      "5     172371\n",
      "3      35793\n",
      "4      19462\n",
      "2      13038\n",
      "7      11137\n",
      "0       2127\n",
      "1       1852\n",
      "8       1191\n",
      "9        133\n",
      "Name: count, dtype: int64\n",
      "10\n",
      "Test: 6    443831\n",
      "5     43110\n",
      "3      8732\n",
      "4      4784\n",
      "2      3315\n",
      "7      2850\n",
      "0       550\n",
      "1       477\n",
      "8       320\n",
      "9        41\n",
      "Name: count, dtype: int64\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame and 'attack_cat' is the target variable\n",
    "X = data.drop(columns=['label', 'attack_cat'])\n",
    "y = data['attack_cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Removing Label Encoder for CatBoost\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "path = './saved_models/label_encoder.joblib'\n",
    "joblib.dump(label_encoder, path)\n",
    "\n",
    "print('Train:', pd.Series(y_train).value_counts())\n",
    "print(len(pd.Series(y_train).value_counts()))\n",
    "print('Test:', pd.Series(y_test).value_counts())\n",
    "print(len(pd.Series(y_test).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff9b0c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.06      0.11       550\n",
      "           1       0.76      0.08      0.14       477\n",
      "           2       0.44      0.29      0.35      3315\n",
      "           3       0.64      0.87      0.74      8732\n",
      "           4       0.77      0.63      0.69      4784\n",
      "           5       1.00      0.99      0.99     43110\n",
      "           6       1.00      1.00      1.00    443831\n",
      "           7       0.92      0.79      0.85      2850\n",
      "           8       0.74      0.86      0.80       320\n",
      "           9       0.70      0.34      0.46        41\n",
      "\n",
      "    accuracy                           0.98    508010\n",
      "   macro avg       0.76      0.59      0.61    508010\n",
      "weighted avg       0.98      0.98      0.98    508010\n",
      "\n",
      "n_samples: 508010\n",
      "n_trees: 100\n",
      "avg_depth: 6\n",
      "Time taken: 1.214368 seconds\n",
      "Estimated GFLOPS: 0.251000\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "#rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# XGBoost \n",
    "rf = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# ExtraTrees\n",
    "#rf = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "#Catboost\n",
    "#rf = CatBoostClassifier(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print('\\nClassification Report (Test Set):')\n",
    "#print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Estimate FLOPs\n",
    "n_samples = X_test.shape[0]\n",
    "n_trees = rf.get_booster().num_boosted_rounds()\n",
    "avg_depth = rf.get_params().get(\"max_depth\") or 6 \n",
    "\n",
    "print(\"n_samples:\", n_samples)\n",
    "print(\"n_trees:\", n_trees)\n",
    "print(\"avg_depth:\", avg_depth)\n",
    "\n",
    "flops = n_samples * n_trees * avg_depth\n",
    "gflops = flops / ((end - start) * 1e9)\n",
    "\n",
    "print(f\"Time taken: {end - start:.6f} seconds\")\n",
    "print(f\"Estimated GFLOPS: {gflops:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3a254e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy per label:\n",
      "Analysis: 0.0600\n",
      "Backdoor: 0.0776\n",
      "DoS: 0.2935\n",
      "Exploits: 0.8715\n",
      "Fuzzers: 0.6269\n",
      "Generic: 0.9858\n",
      "Normal: 0.9982\n",
      "Reconnaissance: 0.7923\n",
      "Shellcode: 0.8625\n",
      "Worms: 0.3415\n",
      "\n",
      "Accuracy per label:\n",
      "Analysis: 0.0600\n",
      "Backdoor: 0.0776\n",
      "DoS: 0.2935\n",
      "Exploits: 0.8715\n",
      "Fuzzers: 0.6269\n",
      "Generic: 0.9858\n",
      "Normal: 0.9982\n",
      "Reconnaissance: 0.7923\n",
      "Shellcode: 0.8625\n",
      "Worms: 0.3415\n"
     ]
    }
   ],
   "source": [
    "#Label Encoded Version\n",
    "accuracy_per_label = {}\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    true_label_indices = np.where(y_test == i)[0]\n",
    "    y_pred_for_label = y_pred[true_label_indices]\n",
    "    correct = np.sum(y_pred_for_label == i)\n",
    "    total = len(true_label_indices)\n",
    "    accuracy_per_label[label] = correct / total\n",
    "print(\"\\nAccuracy per label:\")\n",
    "for label, acc in accuracy_per_label.items():\n",
    "    print(f\"{label}: {acc:.4f}\")\n",
    "\n",
    "\n",
    "##Non Label Encoded Version\n",
    "#accuracy_per_label = {}\n",
    "#labels = np.unique(y_test)  # Get unique class labels directly\n",
    "#\n",
    "#for label in labels:\n",
    "#    true_label_indices = np.where(y_test == label)[0]\n",
    "#    y_pred_for_label = y_pred[true_label_indices]\n",
    "#    correct = np.sum(y_pred_for_label == label)\n",
    "#    total = len(true_label_indices)\n",
    "#    accuracy_per_label[label] = correct / total\n",
    "\n",
    "print(\"\\nAccuracy per label:\")\n",
    "for label, acc in accuracy_per_label.items():\n",
    "    print(f\"{label}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e42b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved_models/SecondaryMulti.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_filename = './saved_models/SecondaryMulti.joblib'\n",
    "#joblib.dump(rf, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc05b3d-bfce-4ed1-83b2-d429f045ee38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bfd09-ce48-4746-9d57-53ce1f87a906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
