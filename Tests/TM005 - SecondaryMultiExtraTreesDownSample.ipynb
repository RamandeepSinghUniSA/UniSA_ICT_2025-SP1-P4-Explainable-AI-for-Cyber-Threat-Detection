{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6a1c99-dee4-42f5-8a19-844fd4cc5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from explainerdashboard import ExplainerDashboard, ClassifierExplainer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import captum.attr as c\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "#Tried these to make increase the performance of the overall model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a61b77a-51ee-4de5-acf9-a406b25a7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matyc\\AppData\\Local\\Temp\\ipykernel_22560\\3121833706.py:1: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Cleaned_full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03af4db2-c403-481a-996e-cad1019ec4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "# Set NA to 0.\n",
    "data['ct_ftp_cmd'] = data['ct_ftp_cmd'].fillna(0)\n",
    "data['attack_cat'] = data['attack_cat'].str.replace(r'\\s+', '', regex=True)\n",
    "data['attack_cat'] = data['attack_cat'].str.replace('Backdoors', 'Backdoor')\n",
    "\n",
    "data = data.drop(columns=['proto', 'dsport', 'service', 'state', 'srcip', 'sport', 'dstip'])\n",
    "\n",
    "temp = data[['is_ftp_login', 'is_sm_ips_ports', 'label', 'attack_cat']]\n",
    "data = data.drop(columns=['is_ftp_login', 'is_sm_ips_ports', 'label', 'attack_cat'])\n",
    "\n",
    "ohe1 = pd.read_csv('../Full_proto_encoded.csv')\n",
    "ohe2 = pd.read_csv('../Full_dsport_encoded.csv')\n",
    "ohe3 = pd.read_csv('../Full_service_encoded.csv')\n",
    "ohe4 = pd.read_csv('../Full_state_encoded.csv')\n",
    "# Spelling error.\n",
    "ohe5 = pd.read_csv('../Full_scrip_encoded.csv')\n",
    "#------------------------------------------#\n",
    "ohe6 = pd.read_csv('../Full_sport_encoded.csv')\n",
    "ohe7 = pd.read_csv('../Full_dstip_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736754f1-5b32-40ab-aba8-2d101dc5feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax seperates Normal data well and reduces noise. Please see Kmeans TSNE evaluation in Archive.\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "data = pd.concat([data, temp, ohe1, ohe2, ohe3, ohe4, ohe5, ohe6, ohe7], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f8f300-b92f-4645-9c2e-fcaf9b528ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame and 'attack_cat' is the target variable\n",
    "X = data.drop(columns=['label', 'attack_cat'])\n",
    "y = data['attack_cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0977106-66d3-4a64-a2c6-9325647aa6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample only 'Normal' in y_train\n",
    "train_df = X_train.copy()\n",
    "train_df['attack_cat'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f168130-88b7-4625-956d-1f308e54e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6    532480\n",
      "5    172371\n",
      "3     35793\n",
      "4     19462\n",
      "2     13038\n",
      "7     11137\n",
      "0      2127\n",
      "1      1852\n",
      "8      1191\n",
      "9       133\n",
      "Name: count, dtype: int64\n",
      "10\n",
      "Test: 6    443831\n",
      "5     43110\n",
      "3      8732\n",
      "4      4784\n",
      "2      3315\n",
      "7      2850\n",
      "0       550\n",
      "1       477\n",
      "8       320\n",
      "9        41\n",
      "Name: count, dtype: int64\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Identify 'Normal' samples\n",
    "normal_samples = train_df[train_df['attack_cat'] == 'Normal']\n",
    "\n",
    "# Identify all other samples\n",
    "non_normal_samples = train_df[train_df['attack_cat'] != 'Normal']\n",
    "\n",
    "# Downsample 'Normal' samples (for example, keep 30%)\n",
    "normal_downsampled = normal_samples.sample(frac=0.3, random_state=42)\n",
    "\n",
    "# Combine back\n",
    "train_df_downsampled = pd.concat([normal_downsampled, non_normal_samples], ignore_index=True)\n",
    "\n",
    "# Shuffle after concatenation\n",
    "train_df_downsampled = train_df_downsampled.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target again\n",
    "X_train = train_df_downsampled.drop(columns=['attack_cat'])\n",
    "y_train = train_df_downsampled['attack_cat']\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Display class distribution in the train set\n",
    "print('Train:', pd.Series(y_train).value_counts())\n",
    "print(len(pd.Series(y_train).value_counts()))\n",
    "print('Test:', pd.Series(y_test).value_counts())\n",
    "print(len(pd.Series(y_test).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004e5dd1-d453-474b-bc82-1df067b7642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test Set):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.43      0.10      0.17       550\n",
      "      Backdoor       0.46      0.03      0.05       477\n",
      "           DoS       0.30      0.26      0.28      3315\n",
      "      Exploits       0.60      0.82      0.69      8732\n",
      "       Fuzzers       0.65      0.82      0.73      4784\n",
      "       Generic       1.00      0.98      0.99     43110\n",
      "        Normal       1.00      1.00      1.00    443831\n",
      "Reconnaissance       0.95      0.74      0.83      2850\n",
      "     Shellcode       0.70      0.71      0.70       320\n",
      "         Worms       0.33      0.02      0.05        41\n",
      "\n",
      "      accuracy                           0.98    508010\n",
      "     macro avg       0.64      0.55      0.55    508010\n",
      "  weighted avg       0.98      0.98      0.98    508010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "#rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# XGBoost \n",
    "#rf = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# ExtraTrees\n",
    "rf = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "#Catboost\n",
    "#rf = CatBoostClassifier(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('\\nClassification Report (Test Set):')\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90d7920-500d-44d1-b236-32736e254df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matyc\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 12.792065000 seconds\n",
      "Approx. GFLOPs: 0.742433\n"
     ]
    }
   ],
   "source": [
    "# Time the prediction with higher precision\n",
    "start = time.perf_counter()\n",
    "y_pred = rf.predict(X_test)\n",
    "end = time.perf_counter()\n",
    "\n",
    "# FLOPs estimation\n",
    "n_samples = X_test.shape[0]\n",
    "n_trees = len(rf.estimators_)\n",
    "avg_depth = np.mean([estimator.get_depth() for estimator in rf.estimators_])\n",
    "\n",
    "flops = n_samples * n_trees * avg_depth\n",
    "gflops = flops / ((end - start) * 1e9)\n",
    "\n",
    "print(f\"Time taken: {end - start:.9f} seconds\")\n",
    "print(f\"Approx. GFLOPs: {gflops:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a86700-6cde-4c39-a2c6-8b9d99596953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy per label:\n",
      "Analysis: 0.1036\n",
      "Backdoor: 0.0252\n",
      "DoS: 0.2582\n",
      "Exploits: 0.8170\n",
      "Fuzzers: 0.8225\n",
      "Generic: 0.9808\n",
      "Normal: 0.9955\n",
      "Reconnaissance: 0.7393\n",
      "Shellcode: 0.7094\n",
      "Worms: 0.0244\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_label = {}\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    true_label_indices = np.where(y_test == i)[0]\n",
    "    y_pred_for_label = y_pred[true_label_indices]\n",
    "    correct = np.sum(y_pred_for_label == i)\n",
    "    total = len(true_label_indices)\n",
    "    accuracy_per_label[label] = correct / total\n",
    "print(\"\\nAccuracy per label:\")\n",
    "for label, acc in accuracy_per_label.items():\n",
    "    print(f\"{label}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e29b09d-c22b-42fe-a32d-5c49e8e426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_filename = './saved_models/SecondaryMulti.joblib'\n",
    "#joblib.dump(rf, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd3804-835f-4313-96d1-cd95108deb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
