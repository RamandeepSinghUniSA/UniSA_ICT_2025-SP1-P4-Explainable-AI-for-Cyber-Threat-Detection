{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class CorrEncoder:\n",
    "    \"\"\"\n",
    "    CorrEncoder: Takes a dataset as input and uses it for the encode function. Encodes the filtered categories then draws correlations.\n",
    "    If correlation is above the threshold adds it to a new dataframe then returns the one hot encoded values with the labels.\n",
    "\n",
    "    Initialisation:\n",
    "        - data (pd.DataFrame): The Dataset that contains the target column and target label variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        # Removes Label for the multi-class processing as it is based on the label category (threat or not).\n",
    "        self.data = self.data.drop(columns=['attack_cat'])\n",
    "\n",
    "    def encode(self, target_column, sparse_n, threshold):\n",
    "        \"\"\"\n",
    "        encode: Takes a target column and target label to encode and draw correlations from. The target column is iterated through\n",
    "        for all categories that contain more positive values than defined in sparse_n. This allows for filtering of sparse categories.\n",
    "        The function then one hot encodes the given category with the static target column and draws correlations for them. If correlation\n",
    "        is greater then threshold then add it to the new DataFrame. The function returns the one hot encoded categories that pass the\n",
    "        threshold with the target label.\n",
    "\n",
    "        The purpose of this function is to resolve the high cardinality problem in one hot encoding.\n",
    "\n",
    "        Parameters:\n",
    "            - target_column (string): The name of the target column. The target column should contain the various categories to encode.\n",
    "            - sparse_n (integer): The minimum amount of positive values required for a category after encoding (deals with sparse categories).\n",
    "            - threshold (float): The threshold for correlation. The function creates onehot encoded columns of all variables that have correlation\n",
    "              higher that the threshold to the target label.\n",
    "\n",
    "        Returns:\n",
    "            - ohe_df (pd.DataFrame): The one hot encoded values from the target column.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert to string to handle duplicates.\n",
    "        self.data[target_column] = self.data[target_column].astype(str)\n",
    "        value_counts = self.data[target_column].value_counts()\n",
    "        #print('Value Counts:', value_counts)\n",
    "        # Check if number of 1s is above the given threshold set by sparse_n.\n",
    "        categories = value_counts[value_counts > sparse_n].index.tolist()\n",
    "        ohe_list = []\n",
    "\n",
    "        # Attack category (target label)\n",
    "        attack_cat = self.data['Label']\n",
    "        \n",
    "        # Go through each unique category in the target column.\n",
    "        for c in categories:\n",
    "            col_name = f'{target_column}_{c}'\n",
    "\n",
    "            # Create the binary encoding column for the current category and target label.\n",
    "            corr_column = (self.data[target_column] == c).astype(int)\n",
    "            correlation = corr_column.corr(attack_cat)\n",
    "\n",
    "            # Check if absolute correlation is greater than threshold.\n",
    "            if abs(correlation) > threshold:\n",
    "                corr_column.name = col_name\n",
    "                ohe_list.append(corr_column)\n",
    "        print('Number of Encoded Features for', target_column)\n",
    "        print(len(ohe_list))\n",
    "        if ohe_list:\n",
    "            # NOTE: This section can be expanded to include print outs but at the moment am focusing on the evaluations.\n",
    "            ohe_df = pd.concat(ohe_list, axis=1)\n",
    "            return ohe_df\n",
    "        else:\n",
    "            # This ommits errors (if really high thresholds are used).\n",
    "            print(\"No correlations exceed the threshold.\")\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(data, type_of, k):\n",
    "    \"\"\"\n",
    "    select_features: Filter data using various feature importance methods.\n",
    "\n",
    "    - 'corr': Filters based on correlation.\n",
    "    - 'ft_importance': Filters using feature importance from Random Forest.\n",
    "    - 'kbest': Filters using Select K-Best from scikit.\n",
    "\n",
    "    Parameters:\n",
    "        - type_of (string): The type of feature importance to measure correlation (corr), feature importance from Random Forest (ft_importance), and Select K-Best (k-best).\n",
    "\n",
    "    Returns:\n",
    "        top_k_features (list): The list of n features.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = data.drop(columns=['attack_cat', 'Label'])\n",
    "    y = data['Label']\n",
    "    \n",
    "    if type_of == 'correlation':\n",
    "        corr_values = {}\n",
    "        for feature in X.columns:\n",
    "            corr_values[feature] = X[feature].corr(y)\n",
    "        corr_data = pd.Series(corr_values).abs()\n",
    "        top_k_features = corr_data.nlargest(k).index.tolist()\n",
    "        return top_k_features\n",
    "\n",
    "    elif type_of == 'ft_importance':\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X, y)\n",
    "        feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "        top_k_features = feature_importances.nlargest(k).index.tolist()\n",
    "        return top_k_features\n",
    "\n",
    "    elif type_of == 'kbest':\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        selector.fit(X, y)\n",
    "        top_k_features = []\n",
    "        selected_mask = selector.get_support()\n",
    "        for i in range(len(selected_mask)):\n",
    "            if selected_mask[i]:\n",
    "                top_k_features.append(X.columns[i])\n",
    "\n",
    "        return top_k_features\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, rs, threshold, downsample, split_method):\n",
    "    \"\"\"\n",
    "    get_data: Preprocess and transform data.\n",
    "    \n",
    "    Parameters:\n",
    "        - size (integer): The size of the validation set.\n",
    "        - rs (int): The random seed to use for sampling and slicing.\n",
    "        - threshold (float): The threshold for correlation when one hot encoding.\n",
    "        - downsample (string, float): Either 'full' or a probability of how much to downsample the labels.\n",
    "        - split_method (string): Slice or sample the data for the validation set.\n",
    "\n",
    "    Returns:\n",
    "        - train_data (pd.DataFrame): The train dataset with labels.\n",
    "        - val_data (pd.DataFrame): The validation dataset with labels.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_names = pd.read_csv('features2.csv')\n",
    "    #self.name = category\n",
    "    feature_names_list = feature_names['Name'].tolist()\n",
    "    datasets = []\n",
    "\n",
    "    # Create a list of datasets.\n",
    "    for i in range(1, 5):\n",
    "        df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n",
    "        df.columns = feature_names_list\n",
    "        df.loc[df['attack_cat'].isnull(), 'attack_cat'] = 'Normal'\n",
    "        datasets.append(df)\n",
    "\n",
    "    # Process each dataset individually this can be increased to more datasets.\n",
    "    for i in range(len(datasets)):\n",
    "        df = datasets[i]\n",
    "            \n",
    "        # Clean the dataset\n",
    "        length1 = len(df)\n",
    "        df['attack_cat'] = df['attack_cat'].str.replace(r'\\s+', '', regex=True)\n",
    "        df['attack_cat'] = df['attack_cat'].str.replace('Backdoors', 'Backdoor')\n",
    "        # Very sparse data.\n",
    "        df = df.drop(columns=['ct_ftp_cmd', 'ct_flw_http_mthd', 'is_ftp_login'])\n",
    "        df = df[~df['sport'].astype(str).str.startswith('0x')]\n",
    "        df = df[~df['sport'].astype(str).str.startswith('-')]\n",
    "        df['sport'] = df['sport'].apply(pd.to_numeric)\n",
    "        df = df[~df['dsport'].astype(str).str.startswith('0x')]\n",
    "        df = df[~df['dsport'].astype(str).str.startswith('-')]\n",
    "        df['dsport'] = df['dsport'].apply(pd.to_numeric)\n",
    "        print(f\"Filtered Rows (Cleaning): {length1 - len(df)}\")\n",
    "\n",
    "        # Full downsampling by matching Normal to Threat (Label).\n",
    "        if downsample == 'full':\n",
    "            threat_rows = df[df['attack_cat'] != 'Normal']\n",
    "            num_threat_rows = len(threat_rows)\n",
    "            print(df['attack_cat'].value_counts())\n",
    "            normal_rows = df[df['attack_cat'] == 'Normal']\n",
    "            sampled_data = normal_rows.sample(n=num_threat_rows, random_state=rs)\n",
    "            df = pd.concat([threat_rows, sampled_data]).reset_index(drop=True)\n",
    "\n",
    "        # Downsample by a given pecentage.\n",
    "        elif downsample is not None:\n",
    "            mask = (df['Label'].shift(-1) != 1) & (df['Label'].shift(1) != 1)\n",
    "            normal_rows = df[(df['attack_cat'] == 'Normal') & mask]\n",
    "            percentage_to_remove = int(len(normal_rows) * downsample)\n",
    "            rows_to_remove = normal_rows.sample(n=percentage_to_remove, random_state=rs)\n",
    "            df = df.drop(rows_to_remove.index)\n",
    "            print(f\"Downsampled Rows: {len(rows_to_remove)}\")\n",
    "\n",
    "        datasets[i] = df\n",
    "    # Combine data.\n",
    "    full_data = pd.concat(datasets).reset_index(drop=True)\n",
    "    categorical_columns = ['state', 'service']\n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype='float32')\n",
    "    encoded_data = encoder.fit_transform(full_data[categorical_columns])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns), index=full_data.index)\n",
    "    full_encoded = pd.concat([full_data.drop(columns=categorical_columns), encoded_df], axis=1)\n",
    "    # Use onehot encoding on categorical values that share high correlation.\n",
    "    encoder = CorrEncoder(full_encoded)\n",
    "    ohe1 = encoder.encode('dsport', 30, threshold)\n",
    "    ohe2 = encoder.encode('proto', 30, threshold)\n",
    "    ohe3 = encoder.encode('sport', 30, threshold)\n",
    "    ohe4 = encoder.encode('srcip', 30, threshold)\n",
    "    ohe5 = encoder.encode('dstip', 30, threshold)\n",
    "    cols_to_drop = ['dsport', 'proto', 'sport', 'srcip', 'dstip']\n",
    "    filtered_data = full_encoded.drop(columns=cols_to_drop)\n",
    "    combined_data = pd.concat([filtered_data, ohe1, ohe2, ohe3, ohe4, ohe5], axis=1)\n",
    "    df_features = combined_data.drop(columns=['attack_cat', 'Label'])\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df_features)\n",
    "    final_data = pd.DataFrame(scaled_data, columns=df_features.columns, index=combined_data.index)\n",
    "    final_data['Label'] = combined_data['Label']\n",
    "    final_data['attack_cat'] = combined_data['attack_cat']\n",
    "\n",
    "    if split_method == 'slice':\n",
    "        slice_size = int(size * len(final_data))\n",
    "        val_start = random.randrange(0, len(final_data) - 2 * slice_size)\n",
    "        val_end = val_start + slice_size\n",
    "        val_data = final_data.iloc[val_start:val_end]\n",
    "        train_data = final_data.drop(val_data.index)\n",
    "    elif split_method == 'shuffle':\n",
    "        train_data, val_data = train_test_split(final_data, test_size=size, random_state=rs)\n",
    "        \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample by 20% of the Normal labels. - 80% of the Normal labels remain.\n",
    "- Lower accuracy on some labels.\n",
    "- Takes a while to encode.\n",
    "- I will do the full data tomorrow morning aswell should be about 70 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_82060\\2847342451.py:24: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n",
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_82060\\2847342451.py:24: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Rows (Cleaning): 67\n",
      "Downsampled Rows: 663712\n",
      "Filtered Rows (Cleaning): 61\n",
      "Downsampled Rows: 627633\n",
      "Filtered Rows (Cleaning): 105\n",
      "Downsampled Rows: 511922\n",
      "Filtered Rows (Cleaning): 75\n",
      "Downsampled Rows: 331833\n",
      "Number of Encoded Features for dsport\n",
      "5\n",
      "Number of Encoded Features for proto\n",
      "3\n",
      "Number of Encoded Features for sport\n",
      "3\n",
      "Number of Encoded Features for srcip\n",
      "19\n",
      "Number of Encoded Features for dstip\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = get_data(\n",
    "    size=0.2,\n",
    "    rs=42,\n",
    "    threshold=0.1,\n",
    "    downsample=0.99,\n",
    "    split_method='shuffle'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Generic           172709\n",
      "Normal             66743\n",
      "Exploits           35383\n",
      "Fuzzers            19340\n",
      "DoS                13000\n",
      "Reconnaissance     11198\n",
      "Analysis            2143\n",
      "Backdoor            1857\n",
      "Shellcode           1197\n",
      "Worms                141\n",
      "Name: count, dtype: int64\n",
      "attack_cat\n",
      "Generic           42772\n",
      "Normal            16613\n",
      "Exploits           9142\n",
      "Fuzzers            4906\n",
      "DoS                3353\n",
      "Reconnaissance     2789\n",
      "Analysis            534\n",
      "Backdoor            472\n",
      "Shellcode           314\n",
      "Worms                33\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "1    256968\n",
      "0     66743\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "1    64315\n",
      "0    16613\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['attack_cat'].value_counts())\n",
    "print(val_data['attack_cat'].value_counts())\n",
    "\n",
    "print(train_data['Label'].value_counts())\n",
    "print(val_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9963574447095205\n",
      "Precision: 0.9856518640180979\n",
      "Recall: 0.9905016972377068\n",
      "F1 Score: 0.9880708294501398\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    357460\n",
      "           1       0.99      0.99      0.99     64222\n",
      "\n",
      "    accuracy                           1.00    421682\n",
      "   macro avg       0.99      0.99      0.99    421682\n",
      "weighted avg       1.00      1.00      1.00    421682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop(columns=['attack_cat', 'Label'])\n",
    "y_train = train_data['Label']\n",
    "train_cat = train_data['attack_cat']\n",
    "X_val = val_data.drop(columns=['attack_cat', 'Label'])\n",
    "y_val = val_data['Label']\n",
    "val_cat = val_data['attack_cat']\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for attack category: Normal\n",
      "Total samples: 357460\n",
      "Correct predictions: 356534\n",
      "Accuracy: 0.997409500363677\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    357460\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00    357460\n",
      "   macro avg       0.50      0.50      0.50    357460\n",
      "weighted avg       1.00      1.00      1.00    357460\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Generic\n",
      "Total samples: 43233\n",
      "Correct predictions: 43225\n",
      "Accuracy: 0.9998149561677422\n",
      "Precision: 1.0\n",
      "Recall: 0.9998149561677422\n",
      "F1-Score: 0.9999074695227741\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00     43233\n",
      "\n",
      "    accuracy                           1.00     43233\n",
      "   macro avg       0.50      0.50      0.50     43233\n",
      "weighted avg       1.00      1.00      1.00     43233\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Fuzzers\n",
      "Total samples: 4740\n",
      "Correct predictions: 4220\n",
      "Accuracy: 0.890295358649789\n",
      "Precision: 1.0\n",
      "Recall: 0.890295358649789\n",
      "F1-Score: 0.9419642857142857\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.89      0.94      4740\n",
      "\n",
      "    accuracy                           0.89      4740\n",
      "   macro avg       0.50      0.45      0.47      4740\n",
      "weighted avg       1.00      0.89      0.94      4740\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: DoS\n",
      "Total samples: 3310\n",
      "Correct predictions: 3309\n",
      "Accuracy: 0.9996978851963746\n",
      "Precision: 1.0\n",
      "Recall: 0.9996978851963746\n",
      "F1-Score: 0.9998489197764012\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      3310\n",
      "\n",
      "    accuracy                           1.00      3310\n",
      "   macro avg       0.50      0.50      0.50      3310\n",
      "weighted avg       1.00      1.00      1.00      3310\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Exploits\n",
      "Total samples: 8795\n",
      "Correct predictions: 8762\n",
      "Accuracy: 0.9962478681068789\n",
      "Precision: 1.0\n",
      "Recall: 0.9962478681068789\n",
      "F1-Score: 0.9981204078145469\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      8795\n",
      "\n",
      "    accuracy                           1.00      8795\n",
      "   macro avg       0.50      0.50      0.50      8795\n",
      "weighted avg       1.00      1.00      1.00      8795\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Reconnaissance\n",
      "Total samples: 2804\n",
      "Correct predictions: 2798\n",
      "Accuracy: 0.9978601997146933\n",
      "Precision: 1.0\n",
      "Recall: 0.9978601997146933\n",
      "F1-Score: 0.9989289539450197\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      2804\n",
      "\n",
      "    accuracy                           1.00      2804\n",
      "   macro avg       0.50      0.50      0.50      2804\n",
      "weighted avg       1.00      1.00      1.00      2804\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Backdoor\n",
      "Total samples: 471\n",
      "Correct predictions: 471\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       471\n",
      "\n",
      "    accuracy                           1.00       471\n",
      "   macro avg       1.00      1.00      1.00       471\n",
      "weighted avg       1.00      1.00      1.00       471\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Analysis\n",
      "Total samples: 519\n",
      "Correct predictions: 483\n",
      "Accuracy: 0.930635838150289\n",
      "Precision: 1.0\n",
      "Recall: 0.930635838150289\n",
      "F1-Score: 0.9640718562874252\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.93      0.96       519\n",
      "\n",
      "    accuracy                           0.93       519\n",
      "   macro avg       0.50      0.47      0.48       519\n",
      "weighted avg       1.00      0.93      0.96       519\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Worms\n",
      "Total samples: 31\n",
      "Correct predictions: 31\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00        31\n",
      "   macro avg       1.00      1.00      1.00        31\n",
      "weighted avg       1.00      1.00      1.00        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Shellcode\n",
      "Total samples: 319\n",
      "Correct predictions: 313\n",
      "Accuracy: 0.9811912225705329\n",
      "Precision: 1.0\n",
      "Recall: 0.9811912225705329\n",
      "F1-Score: 0.990506329113924\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.98      0.99       319\n",
      "\n",
      "    accuracy                           0.98       319\n",
      "   macro avg       0.50      0.49      0.50       319\n",
      "weighted avg       1.00      0.98      0.99       319\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "val_data['predicted_label'] = y_pred\n",
    "val_data['true_label'] = y_val\n",
    "attack_categories = val_data['attack_cat'].unique()\n",
    "for category in attack_categories:\n",
    "    print(f\"Evaluation for attack category: {category}\")\n",
    "    category_data = val_data[val_data['attack_cat'] == category]\n",
    "    if len(category_data) == 0:\n",
    "        print(f\"No samples found for category: {category}\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    y_true_category = category_data['true_label']\n",
    "    y_pred_category = category_data['predicted_label']\n",
    "    correct_predictions = (y_true_category == y_pred_category).sum()\n",
    "    total_samples = len(y_true_category)\n",
    "    accuracy = accuracy_score(y_true_category, y_pred_category)\n",
    "    precision = precision_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    recall = recall_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    f1 = f1_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true_category, y_pred_category, zero_division=0))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample by 50% of the Normal labels. - 50% of the Normal labels remain.\n",
    "- Lower accuracy on some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_18284\\2620974592.py:24: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n",
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_18284\\2620974592.py:24: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Rows (Cleaning): 67\n",
      "Downsampled Rows: 335208\n",
      "Filtered Rows (Cleaning): 61\n",
      "Downsampled Rows: 316986\n",
      "Filtered Rows (Cleaning): 105\n",
      "Downsampled Rows: 258546\n",
      "Filtered Rows (Cleaning): 75\n",
      "Downsampled Rows: 167592\n",
      "Number of Encoded Features for dsport\n",
      "5\n",
      "Number of Encoded Features for proto\n",
      "3\n",
      "Number of Encoded Features for sport\n",
      "3\n",
      "Number of Encoded Features for srcip\n",
      "14\n",
      "Number of Encoded Features for dstip\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = get_data(\n",
    "    size=0.2,\n",
    "    rs=42,\n",
    "    threshold=0.1,\n",
    "    downsample=0.5,\n",
    "    split_method='shuffle'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            912105\n",
      "Generic           172501\n",
      "Exploits           35464\n",
      "Fuzzers            19448\n",
      "DoS                13047\n",
      "Reconnaissance     11153\n",
      "Analysis            2172\n",
      "Backdoor            1860\n",
      "Shellcode           1226\n",
      "Worms                149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9948405991473988\n",
      "Precision: 0.9840936791273894\n",
      "Recall: 0.9925773773399935\n",
      "F1 Score: 0.9883173225906414\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    228019\n",
      "           1       0.98      0.99      0.99     64263\n",
      "\n",
      "    accuracy                           0.99    292282\n",
      "   macro avg       0.99      0.99      0.99    292282\n",
      "weighted avg       0.99      0.99      0.99    292282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop(columns=['attack_cat', 'Label'])\n",
    "y_train = train_data['Label']\n",
    "train_cat = train_data['attack_cat']\n",
    "X_val = val_data.drop(columns=['attack_cat', 'Label'])\n",
    "y_val = val_data['Label']\n",
    "val_cat = val_data['attack_cat']\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for attack category: Normal\n",
      "Total samples: 228019\n",
      "Correct predictions: 226988\n",
      "Accuracy: 0.9954784469715243\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    228019\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00    228019\n",
      "   macro avg       0.50      0.50      0.50    228019\n",
      "weighted avg       1.00      1.00      1.00    228019\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Generic\n",
      "Total samples: 42980\n",
      "Correct predictions: 42978\n",
      "Accuracy: 0.999953466728711\n",
      "Precision: 1.0\n",
      "Recall: 0.999953466728711\n",
      "F1-Score: 0.9999767328230066\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00     42980\n",
      "\n",
      "    accuracy                           1.00     42980\n",
      "   macro avg       0.50      0.50      0.50     42980\n",
      "weighted avg       1.00      1.00      1.00     42980\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Exploits\n",
      "Total samples: 9061\n",
      "Correct predictions: 9032\n",
      "Accuracy: 0.996799470257146\n",
      "Precision: 1.0\n",
      "Recall: 0.996799470257146\n",
      "F1-Score: 0.9983971701763112\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      9061\n",
      "\n",
      "    accuracy                           1.00      9061\n",
      "   macro avg       0.50      0.50      0.50      9061\n",
      "weighted avg       1.00      1.00      1.00      9061\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Fuzzers\n",
      "Total samples: 4798\n",
      "Correct predictions: 4399\n",
      "Accuracy: 0.9168403501458942\n",
      "Precision: 1.0\n",
      "Recall: 0.9168403501458942\n",
      "F1-Score: 0.9566162879199739\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.92      0.96      4798\n",
      "\n",
      "    accuracy                           0.92      4798\n",
      "   macro avg       0.50      0.46      0.48      4798\n",
      "weighted avg       1.00      0.92      0.96      4798\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: DoS\n",
      "Total samples: 3306\n",
      "Correct predictions: 3300\n",
      "Accuracy: 0.9981851179673321\n",
      "Precision: 1.0\n",
      "Recall: 0.9981851179673321\n",
      "F1-Score: 0.9990917347865577\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      3306\n",
      "\n",
      "    accuracy                           1.00      3306\n",
      "   macro avg       0.50      0.50      0.50      3306\n",
      "weighted avg       1.00      1.00      1.00      3306\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Reconnaissance\n",
      "Total samples: 2834\n",
      "Correct predictions: 2831\n",
      "Accuracy: 0.9989414255469301\n",
      "Precision: 1.0\n",
      "Recall: 0.9989414255469301\n",
      "F1-Score: 0.9994704324801412\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      2834\n",
      "\n",
      "    accuracy                           1.00      2834\n",
      "   macro avg       0.50      0.50      0.50      2834\n",
      "weighted avg       1.00      1.00      1.00      2834\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Analysis\n",
      "Total samples: 505\n",
      "Correct predictions: 468\n",
      "Accuracy: 0.9267326732673268\n",
      "Precision: 1.0\n",
      "Recall: 0.9267326732673268\n",
      "F1-Score: 0.9619732785200411\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.93      0.96       505\n",
      "\n",
      "    accuracy                           0.93       505\n",
      "   macro avg       0.50      0.46      0.48       505\n",
      "weighted avg       1.00      0.93      0.96       505\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Shellcode\n",
      "Total samples: 285\n",
      "Correct predictions: 284\n",
      "Accuracy: 0.9964912280701754\n",
      "Precision: 1.0\n",
      "Recall: 0.9964912280701754\n",
      "F1-Score: 0.9982425307557118\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00       285\n",
      "   macro avg       0.50      0.50      0.50       285\n",
      "weighted avg       1.00      1.00      1.00       285\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Worms\n",
      "Total samples: 25\n",
      "Correct predictions: 25\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Backdoor\n",
      "Total samples: 469\n",
      "Correct predictions: 469\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       469\n",
      "\n",
      "    accuracy                           1.00       469\n",
      "   macro avg       1.00      1.00      1.00       469\n",
      "weighted avg       1.00      1.00      1.00       469\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "val_data['predicted_label'] = y_pred\n",
    "val_data['true_label'] = y_val\n",
    "attack_categories = val_data['attack_cat'].unique()\n",
    "for category in attack_categories:\n",
    "    print(f\"Evaluation for attack category: {category}\")\n",
    "    category_data = val_data[val_data['attack_cat'] == category]\n",
    "    if len(category_data) == 0:\n",
    "        print(f\"No samples found for category: {category}\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    y_true_category = category_data['true_label']\n",
    "    y_pred_category = category_data['predicted_label']\n",
    "    correct_predictions = (y_true_category == y_pred_category).sum()\n",
    "    total_samples = len(y_true_category)\n",
    "    accuracy = accuracy_score(y_true_category, y_pred_category)\n",
    "    precision = precision_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    recall = recall_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    f1 = f1_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true_category, y_pred_category, zero_division=0))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample by 90% of the Normal labels. - 10% of the Normal labels remain.\n",
    "- Fixes accuracy to above 99% for all labels except Normal- this might be a problem too?\n",
    "- Decreases accuracy slightly in Normal labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_18284\\2620974592.py:24: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n",
      "C:\\Users\\adi_s\\AppData\\Local\\Temp\\ipykernel_18284\\2620974592.py:24: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'UNSW-NB15_{i}.csv', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Rows (Cleaning): 67\n",
      "Downsampled Rows: 603375\n",
      "Filtered Rows (Cleaning): 61\n",
      "Downsampled Rows: 570575\n",
      "Filtered Rows (Cleaning): 105\n",
      "Downsampled Rows: 465383\n",
      "Filtered Rows (Cleaning): 75\n",
      "Downsampled Rows: 301666\n",
      "Number of Encoded Features for dsport\n",
      "5\n",
      "Number of Encoded Features for proto\n",
      "3\n",
      "Number of Encoded Features for sport\n",
      "3\n",
      "Number of Encoded Features for srcip\n",
      "17\n",
      "Number of Encoded Features for dstip\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = get_data(\n",
    "    size=0.2,\n",
    "    rs=42,\n",
    "    threshold=0.1,\n",
    "    downsample=0.9,\n",
    "    split_method='shuffle'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack_cat\n",
       "Normal            55342\n",
       "Generic           43334\n",
       "Exploits           8882\n",
       "Fuzzers            4711\n",
       "DoS                3308\n",
       "Reconnaissance     2794\n",
       "Analysis            570\n",
       "Backdoor            467\n",
       "Shellcode           305\n",
       "Worms                35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['attack_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9926929886094131\n",
      "Precision: 0.9873728462494438\n",
      "Recall: 0.9991926218054219\n",
      "F1 Score: 0.9932475710548452\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     55342\n",
      "           1       0.99      1.00      0.99     64406\n",
      "\n",
      "    accuracy                           0.99    119748\n",
      "   macro avg       0.99      0.99      0.99    119748\n",
      "weighted avg       0.99      0.99      0.99    119748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop(columns=['attack_cat', 'Label'])\n",
    "y_train = train_data['Label']\n",
    "train_cat = train_data['attack_cat']\n",
    "X_val = val_data.drop(columns=['attack_cat', 'Label'])\n",
    "y_val = val_data['Label']\n",
    "val_cat = val_data['attack_cat']\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for attack category: Generic\n",
      "Total samples: 43334\n",
      "Correct predictions: 43332\n",
      "Accuracy: 0.9999538468638944\n",
      "Precision: 1.0\n",
      "Recall: 0.9999538468638944\n",
      "F1-Score: 0.9999769228994069\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00     43334\n",
      "\n",
      "    accuracy                           1.00     43334\n",
      "   macro avg       0.50      0.50      0.50     43334\n",
      "weighted avg       1.00      1.00      1.00     43334\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Normal\n",
      "Total samples: 55342\n",
      "Correct predictions: 54519\n",
      "Accuracy: 0.9851288352426728\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     55342\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99     55342\n",
      "   macro avg       0.50      0.49      0.50     55342\n",
      "weighted avg       1.00      0.99      0.99     55342\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Reconnaissance\n",
      "Total samples: 2794\n",
      "Correct predictions: 2794\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      2794\n",
      "\n",
      "    accuracy                           1.00      2794\n",
      "   macro avg       1.00      1.00      1.00      2794\n",
      "weighted avg       1.00      1.00      1.00      2794\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Exploits\n",
      "Total samples: 8882\n",
      "Correct predictions: 8879\n",
      "Accuracy: 0.9996622382346319\n",
      "Precision: 1.0\n",
      "Recall: 0.9996622382346319\n",
      "F1-Score: 0.9998310905917459\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      8882\n",
      "\n",
      "    accuracy                           1.00      8882\n",
      "   macro avg       0.50      0.50      0.50      8882\n",
      "weighted avg       1.00      1.00      1.00      8882\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Analysis\n",
      "Total samples: 570\n",
      "Correct predictions: 567\n",
      "Accuracy: 0.9947368421052631\n",
      "Precision: 1.0\n",
      "Recall: 0.9947368421052631\n",
      "F1-Score: 0.9973614775725593\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.99      1.00       570\n",
      "\n",
      "    accuracy                           0.99       570\n",
      "   macro avg       0.50      0.50      0.50       570\n",
      "weighted avg       1.00      0.99      1.00       570\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Fuzzers\n",
      "Total samples: 4711\n",
      "Correct predictions: 4667\n",
      "Accuracy: 0.9906601570791764\n",
      "Precision: 1.0\n",
      "Recall: 0.9906601570791764\n",
      "F1-Score: 0.9953081680528898\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.99      1.00      4711\n",
      "\n",
      "    accuracy                           0.99      4711\n",
      "   macro avg       0.50      0.50      0.50      4711\n",
      "weighted avg       1.00      0.99      1.00      4711\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: DoS\n",
      "Total samples: 3308\n",
      "Correct predictions: 3308\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      3308\n",
      "\n",
      "    accuracy                           1.00      3308\n",
      "   macro avg       1.00      1.00      1.00      3308\n",
      "weighted avg       1.00      1.00      1.00      3308\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Backdoor\n",
      "Total samples: 467\n",
      "Correct predictions: 467\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       467\n",
      "\n",
      "    accuracy                           1.00       467\n",
      "   macro avg       1.00      1.00      1.00       467\n",
      "weighted avg       1.00      1.00      1.00       467\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Shellcode\n",
      "Total samples: 305\n",
      "Correct predictions: 305\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       305\n",
      "\n",
      "    accuracy                           1.00       305\n",
      "   macro avg       1.00      1.00      1.00       305\n",
      "weighted avg       1.00      1.00      1.00       305\n",
      "\n",
      "--------------------------------------------------\n",
      "Evaluation for attack category: Worms\n",
      "Total samples: 35\n",
      "Correct predictions: 35\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "val_data['predicted_label'] = y_pred\n",
    "val_data['true_label'] = y_val\n",
    "attack_categories = val_data['attack_cat'].unique()\n",
    "for category in attack_categories:\n",
    "    print(f\"Evaluation for attack category: {category}\")\n",
    "    category_data = val_data[val_data['attack_cat'] == category]\n",
    "    if len(category_data) == 0:\n",
    "        print(f\"No samples found for category: {category}\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    y_true_category = category_data['true_label']\n",
    "    y_pred_category = category_data['predicted_label']\n",
    "    correct_predictions = (y_true_category == y_pred_category).sum()\n",
    "    total_samples = len(y_true_category)\n",
    "    accuracy = accuracy_score(y_true_category, y_pred_category)\n",
    "    precision = precision_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    recall = recall_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    f1 = f1_score(y_true_category, y_pred_category, zero_division=0)\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true_category, y_pred_category, zero_division=0))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature importances using different measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Label', 'sttl', 'ct_state_ttl', 'state_INT', 'ct_dst_src_ltm', 'ct_dst_sport_ltm', 'proto_tcp', 'swin', 'dwin', 'dmeansz', 'state_FIN', 'ct_src_dport_ltm', 'srcip_175.45.176.1', 'ct_srv_dst', 'ct_srv_src', 'srcip_175.45.176.3', 'dstip_149.171.126.18', 'Dload', 'Ltime', 'Stime', 'ct_src_ ltm', 'ct_dst_ltm', 'service_dns', 'state_CON', 'dsport_53', 'dtcpb', 'stcpb', 'sport_1043', 'proto_udp', 'srcip_175.45.176.0']\n",
      "['Label', 'ct_state_ttl', 'sttl', 'sbytes', 'dbytes', 'dttl', 'dmeansz', 'dur', 'Dload', 'state_INT', 'Dpkts', 'tcprtt', 'smeansz', 'ackdat', 'Sload', 'ct_dst_sport_ltm', 'synack', 'ct_srv_dst', 'srcip_149.171.126.18', 'dloss', 'Djit', 'ct_src_dport_ltm', 'ct_srv_src', 'Sintpkt', 'dstip_175.45.176.3', 'Dintpkt', 'state_FIN', 'sport_0', 'Spkts', 'dstip_175.45.176.1']\n",
      "['sttl', 'Dload', 'swin', 'dwin', 'stcpb', 'dtcpb', 'dmeansz', 'Stime', 'Ltime', 'ct_state_ttl', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'state_CON', 'state_FIN', 'state_INT', 'service_dns', 'dsport_53', 'proto_udp', 'proto_tcp', 'sport_1043', 'srcip_175.45.176.1', 'srcip_175.45.176.3', 'srcip_175.45.176.0', 'dstip_149.171.126.18', 'Label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adi_s\\anaconda3\\envs\\conda311new\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "features1 = select_features(train_data, 'correlation', 30)\n",
    "features2 = select_features(train_data, 'ft_importance', 30)\n",
    "features3 = select_features(train_data, 'kbest', 30)\n",
    "\n",
    "print(features1)\n",
    "print(features2)\n",
    "print(features3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda311new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
