{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations and arrays\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations\n",
    "import seaborn as sns  # For statistical data visualization\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn import metrics  # For model evaluation metrics\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_full_data.csv')\n",
    "print(len(df))\n",
    "df['attack_cat'] = df['attack_cat'].str.replace('Backdoors', 'Backdoor')\n",
    "# Interesting here. I was getting this error when encoding but you seemed to have fixed it.\n",
    "df = df[~df['sport'].astype(str).str.startswith('0x')]\n",
    "df = df[~df['dsport'].astype(str).str.startswith('0x')]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip dsport proto state       dur  sbytes  \\\n",
      "0  59.166.0.0   1390  149.171.126.6     53   udp   CON  0.001055     132   \n",
      "1  59.166.0.0  33661  149.171.126.9   1024   udp   CON  0.036133     528   \n",
      "2  59.166.0.6   1464  149.171.126.7     53   udp   CON  0.001119     146   \n",
      "3  59.166.0.5   3593  149.171.126.5     53   udp   CON  0.001209     132   \n",
      "4  59.166.0.3  49664  149.171.126.0     53   udp   CON  0.001169     146   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0     164    31  ...         0.0           3           7          1   \n",
      "1     304    31  ...         0.0           2           4          2   \n",
      "2     178    31  ...         0.0          12           8          1   \n",
      "3     164    31  ...         0.0           6           9          1   \n",
      "4     178    31  ...         0.0           7           9          1   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \\\n",
      "0           3                 1                 1               1      Normal   \n",
      "1           3                 1                 1               2      Normal   \n",
      "2           2                 2                 1               1      Normal   \n",
      "3           1                 1                 1               1      Normal   \n",
      "4           1                 1                 1               1      Normal   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "attack_cat\n",
      "Normal            2218764\n",
      "Generic            215481\n",
      "Exploits            44525\n",
      "Fuzzers             24246\n",
      "DoS                 16353\n",
      "Reconnaissance      13987\n",
      "Analysis             2677\n",
      "Backdoor             1795\n",
      "Shellcode            1511\n",
      "Backdoors             534\n",
      "Worms                 174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(data, type_of, k):\n",
    "    \"\"\"\n",
    "    select_features: Filter data using various feature importance methods.\n",
    "\n",
    "    - 'corr': Filters based on correlation.\n",
    "    - 'ft_importance': Filters using feature importance from Random Forest.\n",
    "    - 'kbest': Filters using Select K-Best from scikit.\n",
    "\n",
    "    Parameters:\n",
    "        - type_of (string): The type of feature importance to measure correlation (corr), feature importance from Random Forest (ft_importance), and Select K-Best (k-best).\n",
    "\n",
    "    Returns:\n",
    "        top_k_features (list): The list of n features.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = data.drop(columns=['attack_cat', 'Label'])\n",
    "    y = data['Label']\n",
    "    \n",
    "    if type_of == 'correlation':\n",
    "        corr_values = {}\n",
    "        for feature in X.columns:\n",
    "            corr_values[feature] = X[feature].corr(y)\n",
    "        corr_data = pd.Series(corr_values).abs()\n",
    "        top_k_features = corr_data.nlargest(k).index.tolist()\n",
    "        return top_k_features\n",
    "\n",
    "    elif type_of == 'ft_importance':\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X, y)\n",
    "        feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "        top_k_features = feature_importances.nlargest(k).index.tolist()\n",
    "        return top_k_features\n",
    "\n",
    "    elif type_of == 'kbest':\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        selector.fit(X, y)\n",
    "        top_k_features = []\n",
    "        selected_mask = selector.get_support()\n",
    "        for i in range(len(selected_mask)):\n",
    "            if selected_mask[i]:\n",
    "                top_k_features.append(X.columns[i])\n",
    "\n",
    "        return top_k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrEncoder:\n",
    "    \"\"\"\n",
    "    CorrEncoder: Takes a dataset as input and uses it for the encode function. Encodes the filtered categories then draws correlations.\n",
    "    If correlation is above the threshold adds it to a new dataframe then returns the one hot encoded values with the labels.\n",
    "\n",
    "    Initialisation:\n",
    "        - data (pd.DataFrame): The Dataset that contains the target column and target label variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        # Removes Label for the multi-class processing as it is based on the label category (threat or not).\n",
    "        self.data = self.data.drop(columns=['attack_cat'])\n",
    "\n",
    "    def encode(self, target_column, sparse_n, threshold, print_data):\n",
    "        \"\"\"\n",
    "        encode: Takes a target column and target label to encode and draw correlations from. The target column is iterated through\n",
    "        for all categories that contain more positive values than defined in sparse_n. This allows for filtering of sparse categories.\n",
    "        The function then one hot encodes the given category with the static target column and draws correlations for them. If correlation\n",
    "        is greater then threshold then add it to the new DataFrame. The function returns the one hot encoded categories that pass the\n",
    "        threshold with the target label.\n",
    "\n",
    "        The purpose of this function is to resolve the high cardinality problem in one hot encoding.\n",
    "\n",
    "        Parameters:\n",
    "            - target_column (string): The name of the target column. The target column should contain the various categories to encode.\n",
    "            - sparse_n (integer): The minimum amount of positive values required for a category after encoding (deals with sparse categories).\n",
    "            - threshold (float): The threshold for correlation. The function creates onehot encoded columns of all variables that have correlation\n",
    "              higher that the threshold to the target label.\n",
    "\n",
    "        Returns:\n",
    "            - ohe_df (pd.DataFrame): The one hot encoded values from the target column.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data[target_column] = self.data[target_column].astype(str)\n",
    "        value_counts = self.data[target_column].value_counts()\n",
    "        # Check if number of 1s is above the given threshold set by sparse_n.\n",
    "        categories = value_counts[value_counts > sparse_n].index.tolist()\n",
    "        ohe_list = []\n",
    "        # Attack category for multi-class binary.\n",
    "        attack_cat = self.data['label']\n",
    "        \n",
    "        # Go through each unique category in the target column.\n",
    "        for c in categories:\n",
    "            col_name = f'{target_column}_{c}'\n",
    "\n",
    "            # Create the binary encoding column for the current category and target label.\n",
    "            corr_column = (self.data[target_column] == c).astype(int)\n",
    "            correlation = corr_column.corr(attack_cat)\n",
    "\n",
    "            # Check if absolute correlation is greater than threshold.\n",
    "            if abs(correlation) > threshold:\n",
    "                corr_column.name = col_name\n",
    "                ohe_list.append(corr_column)\n",
    "        if print_data:\n",
    "            print('Number of Encoded Features for', target_column)\n",
    "            print(len(ohe_list))\n",
    "        if ohe_list:\n",
    "            # NOTE: This section can be expanded to include print outs but at the moment am focusing on the evaluations.\n",
    "            ohe_df = pd.concat(ohe_list, axis=1)\n",
    "            return ohe_df\n",
    "        else:\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_df = pd.read_csv('NUSW-NB15_features.csv', encoding='ISO-8859-1')\n",
    "feature_names_df['Name'] = feature_names_df['Name'].str.strip().str.lower().str.replace(' ', '')\n",
    "\n",
    "df = pd.read_csv('Cleaned_full_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Count the number of categorical and numerical features\n",
    "num_categorical_features = len(categorical_features)\n",
    "num_numerical_features = len(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Encoded Features for dsport\n",
      "3\n",
      "Number of Encoded Features for proto\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m ohe1 \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdsport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m, threshold, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m ohe2 \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m, threshold, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m ohe3 \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msport\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m ohe4 \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrcip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m, threshold, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m ohe5 \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdstip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m, threshold, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36mCorrEncoder.encode\u001b[1;34m(self, target_column, sparse_n, threshold, print_data)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Create the binary encoding column for the current category and target label.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m corr_column \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[target_column] \u001b[38;5;241m==\u001b[39m c)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m correlation \u001b[38;5;241m=\u001b[39m \u001b[43mcorr_column\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattack_cat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Check if absolute correlation is greater than threshold.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(correlation) \u001b[38;5;241m>\u001b[39m threshold:\n",
      "File \u001b[1;32mc:\\Users\\adi_s\\anaconda3\\envs\\conda311new\\Lib\\site-packages\\pandas\\core\\series.py:2973\u001b[0m, in \u001b[0;36mSeries.corr\u001b[1;34m(self, other, method, min_periods)\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(this) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m-> 2973\u001b[0m this_values \u001b[38;5;241m=\u001b[39m \u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2974\u001b[0m other_values \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkendall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(method):\n",
      "File \u001b[1;32mc:\\Users\\adi_s\\anaconda3\\envs\\conda311new\\Lib\\site-packages\\pandas\\core\\base.py:656\u001b[0m, in \u001b[0;36mIndexOpsMixin.to_numpy\u001b[1;34m(self, dtype, copy, na_value, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fillna:\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m can_hold_element(values, na_value):\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;66;03m# if we can't hold the na_value asarray either makes a copy or we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;66;03m# error before modifying values. The asarray later on thus won't make\u001b[39;00m\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;66;03m# another copy\u001b[39;00m\n\u001b[1;32m--> 656\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "categorical_columns = ['state', 'service']\n",
    "# There is not many unique values here so it works ok.\n",
    "encoder = OneHotEncoder(sparse_output=False, dtype='float32')\n",
    "encoded_data = encoder.fit_transform(df[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns), index=df.index)\n",
    "full_encoded = pd.concat([df.drop(columns=categorical_columns), encoded_df], axis=1)\n",
    "\n",
    "# Select correlation threshold. All values with correlation less than threshold to the label are not encoded.\n",
    "# NOTE: Decreasing threshold 0.01 or lower significantly increases the number of columns. I think 0.01 was around 244 for downsampled but it usually is more for\n",
    "# full data.\n",
    "threshold = 0.1\n",
    "encoder = CorrEncoder(full_encoded)\n",
    "ohe1 = encoder.encode('dsport', 30, threshold, True)\n",
    "ohe2 = encoder.encode('proto', 30, threshold, True)\n",
    "ohe3 = encoder.encode('sport', 30, threshold, True)\n",
    "ohe4 = encoder.encode('srcip', 30, threshold, True)\n",
    "ohe5 = encoder.encode('dstip', 30, threshold, True)\n",
    "cols_to_drop = ['dsport', 'proto', 'sport', 'srcip', 'dstip']\n",
    "filtered_data = full_encoded.drop(columns=cols_to_drop)\n",
    "combined_data = pd.concat([filtered_data, ohe1, ohe2, ohe3, ohe4, ohe5], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of Downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Downsample\n",
    "#threat_rows = df[df['attack_cat'] != 'Normal']\n",
    "#num_threat_rows = len(threat_rows)\n",
    "#print(df['attack_cat'].value_counts())\n",
    "#normal_rows = df[df['attack_cat'] == 'Normal']\n",
    "#sampled_data = normal_rows.sample(n=num_threat_rows, random_state=rs)\n",
    "#df = pd.concat([threat_rows, sampled_data]).reset_index(drop=True)\n",
    "\n",
    "# Choose a random seed.\n",
    "rs = 42\n",
    "\n",
    "# Select proportion to downsample by.\n",
    "downsample = 0.5\n",
    "mask = (df['Label'].shift(-1) != 1) & (df['Label'].shift(1) != 1)\n",
    "normal_rows = df[(df['attack_cat'] == 'Normal') & mask]\n",
    "percentage_to_remove = int(len(normal_rows) * downsample)\n",
    "rows_to_remove = normal_rows.sample(n=percentage_to_remove, random_state=rs)\n",
    "df = df.drop(rows_to_remove.index)\n",
    "print(f\"Downsampled Rows: {len(rows_to_remove)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda311new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
