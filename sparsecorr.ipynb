{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations and arrays\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations\n",
    "import seaborn as sns  # For statistical data visualization\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn import metrics  # For model evaluation metrics\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting in Jupyter notebooks\n",
    "# Fixed duplicate import and invalid syntax\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Reading datasets\n",
    "# Using list comprehension to read all csv files in 4 csv files\n",
    "dataframes = [pd.read_csv(f'UNSW-NB15_{i}.csv', header=None) \n",
    "       for i in range(1,5)]\n",
    "    \n",
    "# Concat all to a single df name combined_data\n",
    "# Resetting index is important because:\n",
    "# 1. When concatenating dataframes, the original index values are preserved which can lead to duplicate indices\n",
    "# 2. Duplicate indices can cause issues with data access, filtering and analysis\n",
    "# 3. reset_index() creates a clean, sequential index starting from 0\n",
    "combined_data = pd.concat(dataframes).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts null labels to normal.\n",
    "feature_names = pd.read_csv('features2.csv' )\n",
    "feature_names_list = feature_names['Name'].tolist()\n",
    "combined_data.columns = feature_names_list\n",
    "combined_data.loc[combined_data['attack_cat'].isnull(), 'attack_cat'] = 'Normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of just sport and attack cat columns for function.\n",
    "df1 = combined_data[['sport', 'attack_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal              2218764\n",
      "Generic              215481\n",
      "Exploits              44525\n",
      " Fuzzers              19195\n",
      "DoS                   16353\n",
      " Reconnaissance       12228\n",
      " Fuzzers               5051\n",
      "Analysis               2677\n",
      "Backdoor               1795\n",
      "Reconnaissance         1759\n",
      " Shellcode             1288\n",
      "Backdoors               534\n",
      "Shellcode               223\n",
      "Worms                   174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Label correction.\n",
    "print(df1['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['attack_cat'] = df1['attack_cat'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            2218764\n",
      "Generic            215481\n",
      "Exploits            44525\n",
      "Fuzzers             24246\n",
      "DoS                 16353\n",
      "Reconnaissance      13987\n",
      "Analysis             2677\n",
      "Backdoor             1795\n",
      "Shellcode            1511\n",
      "Backdoors             534\n",
      "Worms                 174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sport\n",
      "1043     216289\n",
      "47439    198580\n",
      "0         50432\n",
      "47439      4689\n",
      "1043       4033\n",
      "          ...  \n",
      "33785         1\n",
      "2637          1\n",
      "29900         1\n",
      "3664          1\n",
      "706           1\n",
      "Name: count, Length: 100341, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['sport'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a smaller dataframe to make function.\n",
    "df1 = df1.head(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100287\n"
     ]
    }
   ],
   "source": [
    "# Check number of unique categories in sport (reduced data).\n",
    "sports = df1['sport'].unique()\n",
    "print(len(sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sport\n",
      "0        8910\n",
      "47439    4689\n",
      "1043     4033\n",
      "0        3612\n",
      "47439    2250\n",
      "         ... \n",
      "49266       1\n",
      "39428       1\n",
      "3044        1\n",
      "62086       1\n",
      "27909       1\n",
      "Name: count, Length: 100287, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['sport'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only values that appear more than 30 times.\n",
    "sports = df1['sport'].value_counts()[df1['sport'].value_counts() > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556\n"
     ]
    }
   ],
   "source": [
    "print(len(sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation in Sport Column:\n",
      "     Sport  Correlation\n",
      "16      68     0.016251\n",
      "17      68     0.016251\n",
      "2     4033     0.001546\n",
      "5     1930     0.000692\n",
      "3     3612     0.000674\n",
      "..     ...          ...\n",
      "551     31          NaN\n",
      "552     31          NaN\n",
      "553     31          NaN\n",
      "554     31          NaN\n",
      "555     31          NaN\n",
      "\n",
      "[556 rows x 2 columns]\n",
      "     Sport  Correlation\n",
      "551     31          NaN\n",
      "552     31          NaN\n",
      "553     31          NaN\n",
      "554     31          NaN\n",
      "555     31          NaN\n",
      "sport\n",
      "0        8910\n",
      "47439    4689\n",
      "1043     4033\n",
      "0        3612\n",
      "47439    2250\n",
      "         ... \n",
      "49266       1\n",
      "39428       1\n",
      "3044        1\n",
      "62086       1\n",
      "27909       1\n",
      "Name: count, Length: 100287, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The label we want to compare.\n",
    "label = 'Normal'\n",
    "# Dataframe to add the correlations.\n",
    "corr_df = pd.DataFrame(index=df1.index)\n",
    "corr_list = []\n",
    "# Go through each unique category in the given column (tested on just sport but can make it a function).\n",
    "for s in sports:\n",
    "    # Create column name same as encoding conventions.\n",
    "    col_name = f'sport_{s}'\n",
    "    # Convert all values that match to 1 or else convert to 0 for given values in each column (sport is an iteration and label is static).\n",
    "    corr_df[col_name] = (df1['sport'] == s).astype(int)\n",
    "    attack_cat = (df1['attack_cat'] == label).astype(int)\n",
    "    # Draw correlations of the converted binary columns.\n",
    "    correlation = corr_df[col_name].corr(attack_cat)\n",
    "    # Add correlations to list for Dataframe.\n",
    "    corr_list.append({\n",
    "        'Sport': s,\n",
    "        'Correlation': correlation\n",
    "    })\n",
    "corr_table = pd.DataFrame(corr_list)\n",
    "# Get the absolute correlation and sort in descending order.\n",
    "corr_table['Correlation'] = corr_table['Correlation'].abs()\n",
    "corr_table.sort_values(by='Correlation', ascending=False, inplace=True)\n",
    "print(\"\\nCorrelation in Sport Column:\")\n",
    "print(corr_table)\n",
    "print(corr_table.tail())\n",
    "print(df1['sport'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda311new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
